\section*{Lecture 1}

\subsection*{1)}
Let
\[ 
A = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix}, \quad B = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix}, \quad C = \begin{pmatrix}
2 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2\\
\end{pmatrix}
.\]
Calculate $CC$, $CCC$, $AC$, $BC$, $(A+B)C$, $AA$, $BB$, $AB$, $BA$, $A A^{T}$, $BB^{T}$, $(AB)^{T}$.


\paragraph{CC.} We have that
\[ 
C C = \begin{pmatrix}
2 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2\\
\end{pmatrix} \cdot \begin{pmatrix}
2 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2\\
\end{pmatrix} = \begin{pmatrix}
2\cdot 2 + 0 \cdot 0 + 0 \cdot 0 & 2\cdot 0 + 0 \cdot 1 + 0 \cdot 0 & 2 \cdot 0 + 0 \cdot 0 + 0 \cdot 2\\
0 \cdot 2 + 1 \cdot 0 + 0 \cdot 0 & 0 \cdot 0 + 1 \cdot 1 + 0 \cdot 0 & 0 \cdot 0 + 1 \cdot 0 + 0 \cdot 2\\
0 \cdot 2 + 0 \cdot 0 + 2\cdot 0 & 0 \cdot 0 + 0 \cdot 1 + 0 \cdot 0 & 0 \cdot 0 + 0 \cdot 0 + 2 \cdot 2\\
\end{pmatrix}
.\]
The above result can be simplified to
\[ 
C C = \begin{pmatrix}
4 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 4\\
\end{pmatrix}
.\]
It can now be observed that multiplying a diagonal matrix with another diagonal matrix can, informally, be understood as just multiplying the entries on the diagonal with each other.

\paragraph{CCC.} We can reuse the result from before like
\[ 
C C C= \begin{pmatrix}
4 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 4\\
\end{pmatrix} C = \begin{pmatrix}
8 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 8\\
\end{pmatrix}
.\]

\paragraph{AC.} We now have that
\[ 
AC = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} \begin{pmatrix}
2 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2\\
\end{pmatrix} = \begin{pmatrix}
1\cdot 2 + 1 \cdot 0 + 2 \cdot 0 & 1 \cdot 0 + 1 \cdot 1 + 2 \cdot 0 & 1 \cdot 0 + 1 \cdot 0 + 2 \cdot 2\\
0 \cdot 2 + 2 \cdot 0 + 1 \cdot 0 & 0 \cdot 0 + 2 \cdot 1 + 0 \cdot 0 & 0 \cdot 0 + 2 \cdot 0 + 1 \cdot 2\\
0 \cdot 2 + 0 \cdot 0 + 1 \cdot 0 & 0 \cdot 0 + 0 \cdot 1 + 1 \cdot 0 & 0 \cdot 0 + 0 \cdot  0 + 1 \cdot 2 \\
\end{pmatrix}
.\]
The above result can be simplified to
\[ 
AC = \begin{pmatrix}
2 & 1 & 4\\
0 & 2 & 2\\
0 & 0 & 2\\
\end{pmatrix}
.\]

\paragraph{BC.} We have that
\[ 
BC = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} \begin{pmatrix}
2 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2\\
\end{pmatrix} = \begin{pmatrix}
1 \cdot 2 + 0 \cdot 0 + 0 \cdot 0 & 1 \cdot 0 + 0 \cdot 1 + 0 \cdot 0 & 1 \cdot 0 + 0 \cdot 0 + 0 \cdot 2\\
2 \cdot 2 + 1 \cdot 0 + 0 \cdot 0 & 2 \cdot 0 + 1 \cdot 1 + 0 \cdot 0 & 2 \cdot 0 + 1 \cdot 0 + 0 \cdot 2\\
1 \cdot 2 + 2 \cdot 0 + 2 \cdot 0 & 1 \cdot 0 + 2 \cdot 1 + 2 \cdot 0 & 1 \cdot 0 + 2 \cdot 0 + 2 \cdot 2\\
\end{pmatrix}
.\]
Which can be rewritten as
\[ 
BC = \begin{pmatrix}
2 & 0 & 0\\
4 & 1 & 0\\
2 & 2 & 4\\
\end{pmatrix}
.\]

\paragraph{(A+B)C.} We start by calculating the sum like
\[ 
A + B = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} + \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} = \begin{pmatrix}
2 & 1 & 2\\
2 & 3 & 1\\
1 & 2 & 3\\
\end{pmatrix}
.\]
This can now be multiplied with $C$ like
\[ 
  (A+B)C = \begin{pmatrix}
  2 & 1 & 2\\
  2 & 3 & 1\\
  1 & 2 & 3\\
  \end{pmatrix} \begin{pmatrix}
  2 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 2\\
  \end{pmatrix} = \begin{pmatrix}
  2 \cdot 2 + 1 \cdot 0 + 2 \cdot 0 & 2 \cdot 0 + 1 \cdot 1 + 2 \cdot 0 & 2 \cdot 0 + 1 \cdot 0 + 2 \cdot 2\\
  2 \cdot 2 + 3 \cdot 0 + 1 \cdot 0 & 2 \cdot 0 + 3 \cdot 1 + 1 \cdot 0 & 2 \cdot 0 + 3 \cdot 0 + 1 \cdot 2\\
  1 \cdot 2 + 2 \cdot 0 + 3 \cdot 0 & 1 \cdot 0 + 2 \cdot 1 + 3 \cdot 0 & 1 \cdot 0 + 2 \cdot 0 + 3 \cdot 2\\
  \end{pmatrix}
.\]
Which is just
\[ 
  (A+B)C = \begin{pmatrix}
  4 & 1 & 4\\
  4 & 3 & 2\\
  2 & 2 & 6\\
  \end{pmatrix}
.\]

\paragraph{AA.} This time we have
\[ 
A A = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} = \begin{pmatrix}
1 \cdot 1 + 1 \cdot 0 + 2 \cdot 0 & 1 \cdot 1 + 1 \cdot 2 + 2 \cdot 0 & 1 \cdot 2 + 1 \cdot 1 + 2 \cdot 1\\
0 \cdot  1 + 2 \cdot 0 + 1 \cdot 0 & 0 \cdot 1 + 2 \cdot 2 + 1 \cdot 0 & 0 \cdot 2 + 2 \cdot 1 + 1 \cdot 1\\
0 \cdot 2 + 0 \cdot 1 + 1 \cdot 0 & 0 \cdot 1 + 0 \cdot 2 + 1 \cdot 0 & 0 \cdot 2 + 0 \cdot 1 + 1 \cdot 1\\
\end{pmatrix}
.\]
Which can be written as
\[ 
A A = \begin{pmatrix}
1 & 3 & 5\\
0 & 4 & 3\\
0 & 0 & 1\\
\end{pmatrix}
.\]
A result like that for diagonal matrices can be noted for products of matrices with triangularity in the same ``direction'' -- the empty-triangle will stay empty after multiplication.


\paragraph{BB.} This time we get
\[ 
B B = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} = \begin{pmatrix}
1 \cdot 1 + 0 \cdot 2 + 0 \cdot 1 & 1 \cdot 0 + 0 \cdot 1 + 0 \cdot 2 & 1 \cdot 0 + 0 \cdot 0 + 0 \cdot 2\\
2 \cdot 1 + 1 \cdot 2 + 0 \cdot 1 & 2 \cdot 0 + 1 \cdot 1 + 0 \cdot 2 & 2 \cdot 0 + 1 \cdot 0 + 0 \cdot 2\\
1 \cdot 1 + 2 \cdot 2 + 2 \cdot 1 & 1 \cdot 0 + 2 \cdot 1 + 2 \cdot 2 & 1 \cdot 0 + 2 \cdot 0 + 2 \cdot 2 \\
\end{pmatrix}
.\]
Which can be simplified to
\[ 
B B = \begin{pmatrix}
1 & 0 & 0\\
4 & 1 & 0\\
7 & 6 & 4\\
\end{pmatrix}
.\]


\paragraph{AB.} This time we get
\[ 
AB = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} = \begin{pmatrix}
1 + 2 + 2 & 0 + 1 + 4 & 0 + 0 + 4 \\
0 + 4 + 1 & 0 + 2 + 2 & 0 + 0 + 2 \\
0 + 0 + 1 & 0 + 0 + 2 & 0 + 0 + 2\\
\end{pmatrix} = \begin{pmatrix}
5 & 5 & 4\\
5 & 4 & 2\\
1 & 2 & 2\\
\end{pmatrix}
.\]


\paragraph{BA.} This time we get
\[ 
BA = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} = \begin{pmatrix}
1 + 0 + 0 & 1 + 0 + 0 & 2 + 0 + 0 \\
2 + 0 + 0 & 2 + 2 + 0 & 4 + 1 + 0\\
1 + 0 + 0 & 1 + 4 + 0 & 2 + 2 + 2\\
\end{pmatrix} = \begin{pmatrix}
1 & 1 & 2\\
2 & 4 & 5\\
1 & 5 & 6\\
\end{pmatrix}
.\]

\paragraph{AA$^T$.} We start by finding the transpose of $A$, $A^T$, like
\[ 
A = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} \implies A^T = \begin{pmatrix}
1 & 0 & 0\\
1 & 2 & 0\\
2 & 1 & 1\\
\end{pmatrix}
.\]
Now we can calculate the product like normally. So
\[ 
A A^T = \begin{pmatrix}
1 & 1 & 2\\
0 & 2 & 1\\
0 & 0 & 1\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
1 & 2 & 0\\
2 & 1 & 1\\
\end{pmatrix} = \begin{pmatrix} 1 + 1 + 4 & 0 + 2 + 2 & 0 + 0 + 2\\
0 + 2 + 2 & 0 + 4 + 1 & 0 + 0 + 1\\
0 + 0 + 2 & 0 + 0 + 1 & 0 + 0 + 1\\
\end{pmatrix} = \begin{pmatrix}
6 & 4 & 2\\
4 & 5 & 1\\
2 & 1 & 1\\
\end{pmatrix}
.\]

\paragraph{BB$^{T}$.} The same procedure as above can be used
\[ 
BB^{T} = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
1 & 2 & 2\\
\end{pmatrix} \begin{pmatrix}
1 & 2 & 1\\
0 & 1 & 2\\
0 & 0 & 2\\
\end{pmatrix} = \begin{pmatrix}
1 + 0 + 0 & 2 + 0 + 0 & 1 + 0 + 0\\
2 + 0 + 0 & 4 + 1 + 0 & 2 + 2 + 0\\
1 + 0 + 0 & 2 + 2 + 0 & 1 + 4 + 4\\
\end{pmatrix} = \begin{pmatrix}
1 & 2 & 1\\
2 & 5 & 4\\
1 & 4 & 9\\
\end{pmatrix}
.\]

\paragraph{AB$^{T}$.} We have already calculated $AB$ to be
\[ 
AB = \begin{pmatrix}
5 & 5 & 4\\
5 & 4 & 2\\
1 & 2 & 2\\
\end{pmatrix}
.\]
This can now just be transposed like
\[ 
  (AB)^{T} = \begin{pmatrix}
  5 & 5 & 1\\
  5 & 4 & 2\\
  4 & 2 & 2\\
  \end{pmatrix}
.\]




\subsection*{2)}
Let
\[ 
A = \begin{pmatrix}
1 & 1\\
0 & 2\\
0 & 0\\
\end{pmatrix}, \quad B = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
\end{pmatrix}, \quad \Vec{x} = \begin{pmatrix}
1\\
2\\
3\\
\end{pmatrix}
.\]
Calculate $A A^T$, $A^T A$, $BB^{T}$, $B^{T}B$, $AB$, $B^{T}A^{T}$, $B \Vec{x}$, $\Vec{x}^{T}A$, $\Vec{x} \Vec{x}^{T}$, $\Vec{x}^{T} \Vec{x}$.

\paragraph{AA$^T$.}
\[ 
A A^{T}= \begin{pmatrix}
1 & 1\\
0 & 2\\
0 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
1 & 2 & 0\\
\end{pmatrix} = \begin{pmatrix}
1 + 1 & 0 + 2 & 0 + 0\\
0 + 2 & 0 + 4 & 0 + 0 \\
0 + 0 & 0 + 0 & 0 + 0\\
\end{pmatrix} = \begin{pmatrix}
2 & 2 & 0\\
2 & 4 & 0\\
0 & 0 & 0\\
\end{pmatrix}
.\]

\paragraph{A$^T$ A.}
\[ 
A^{T} A = \begin{pmatrix}
1 & 0 & 0\\
1 & 2 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 1\\
0 & 2\\
0 & 0\\
\end{pmatrix} = \begin{pmatrix}
1 + 0 + 0 & 1 + 0 + 0\\
1 + 0 + 0 & 1 + 4 + 0\\
\end{pmatrix} = \begin{pmatrix}
1 & 1\\
1 & 5\\
\end{pmatrix}
.\]

\paragraph{BB$^T$.}
\[ 
B B^{T} = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 2\\
0 & 1\\
0 & 0\\
\end{pmatrix} = \begin{pmatrix}
1 & 2 \\
2 & 5 \\
\end{pmatrix}
.\]

\paragraph{B$^T$B.}
\[ 
B^{T}B = \begin{pmatrix}
1 & 2\\
0 & 1\\
0 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
\end{pmatrix} = \begin{pmatrix}
5 & 2 & 0\\
2 & 1 & 0\\
0 & 0 & 0\\
\end{pmatrix}
.\]

\paragraph{AB.}
\[ 
AB = \begin{pmatrix}
1 & 1\\
0 & 2\\
0 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
\end{pmatrix} = \begin{pmatrix}
3 & 1 & 0\\
4 & 2 & 0\\
0 & 0 & 0\\
\end{pmatrix}
.\]

\paragraph{B$^T$A$^T$.}
\[ 
B^TA^T = \begin{pmatrix}
1 & 2\\
0 & 1\\
0 & 0\\
\end{pmatrix} \begin{pmatrix}
1 & 0 & 0\\
1 & 2 & 0\\
\end{pmatrix} = \begin{pmatrix}
3 & 4 & 0\\
1 & 2 & 0\\
0 & 0 & 0\\
\end{pmatrix}
.\]

\paragraph{B$\Vec{x}$.}
\[ 
B \Vec{x} = \begin{pmatrix}
1 & 0 & 0\\
2 & 1 & 0\\
\end{pmatrix} \begin{pmatrix}
1\\
2\\
3\\
\end{pmatrix} = \begin{pmatrix}
1\\
4\\
\end{pmatrix}
.\]

\paragraph{$\Vec{x}^TA$.}
\[ 
\Vec{x}^T A = \begin{pmatrix}
1 & 2 & 3\\
\end{pmatrix} \begin{pmatrix}
1 & 1\\
0 & 2\\
0 & 0\\
\end{pmatrix} = \begin{pmatrix}
1 & 5\\
\end{pmatrix}
.\]


\paragraph{$\Vec{x}\Vec{x}^T$.}
\[ 
\Vec{x}\Vec{x}^T = \begin{pmatrix}
1\\
2\\
3\\
\end{pmatrix} \begin{pmatrix}
1 & 2 & 3\\
\end{pmatrix} = \begin{pmatrix}
1 & 2 & 3\\
2 & 4 & 6\\
3 & 6 & 9\\
\end{pmatrix}
.\]

\paragraph{$\Vec{x}^T \Vec{x}$}
\[ 
\Vec{x}^T \Vec{x} = \begin{pmatrix}
1 & 2 & 3\\
\end{pmatrix} \begin{pmatrix}
1\\
2\\
3\\
\end{pmatrix} = 14
.\]



\subsection*{3)}
Let $A$ be an $m \times n$ matrix, $B$ be an $p \times q$  matrix and $C$ be an $r\times s$ matrix. Derive conditions on $m, n, p, q, r, s$ such that
\[ 
  \left( AB \right) \left( CA^{T} \right)
\]
is well-defined.
\bigbreak
For $AB$ to be defined $m \times n$ must fit $p \times q$; it must be true that the number of columns in $A$ ($n$) is equal to the number of rows in $B$ ($p$). That is $n = p$.

Likewise for $CA^T$ to be defined the number of columns in $C$ ($s$) must equal the number of rows in $A^T$ ($n$). That is $s = n$.

We can also observe that $AB$ is an $m \times q$ matrix and $CA^T$ is an $r \times m$ matrix.

For the product of an $m \times q$ matrix ($AB$) and an $r \times m$ matrix ($CA^T$) to be defined it must be true that $q = r$.

That is all in all $n = p = s, \, q = r$.

3\cdot4-5 = -60
